#!/usr/bin/env python3
# encoding: utf-8 (as per PEP 263)

import sys

import requests
from bs4 import BeautifulSoup

urls = [
    'http://www.fim.uni-passau.de/studium/modulkataloge/',
    'http://www.fim.uni-passau.de/index.php?id=17010',
    'http://www.fim.uni-passau.de/ueber-die-fakultaet/ausschuesse/pruefungsausschuss/',
]

def parse_lolol(soup):
    """Parse list of lists of links. Requires full page soup as input."""
    
    pagetitle = soup.find('header', {'class': 'up-page-content-pagetitle'}).find('h1').get_text()
    print('# %s' % pagetitle)
    print()
    
    content = soup.find('div', {'class': 'up-page-content-column-center'})

    for l in content.find_all('ul'):
        heading = l.find_previous(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']).get_text()
        print('## %s' % heading)
        for i in l.find_all('li'):
            text = i.get_text()
            a = i.find('a')
            if not a:
                print('* %s  ' % (text))
            else:
                href = i.find('a').attrs['href']
                if not href.startswith('http://'):
                    href = 'http://www.fim.uni-passau.de/' + href
                print('* %s  \n  %s' % (text, href))
        print()

def main():
    for url in urls:
        req = requests.get(url)
        soup = BeautifulSoup(req.content, 'lxml')
        parse_lolol(soup)

if __name__ == '__main__':
    main()
